{"cells":[{"cell_type":"markdown","id":"1122bff3-d09c-4954-a089-b4b4872c8b27","metadata":{"id":"1122bff3-d09c-4954-a089-b4b4872c8b27"},"source":["# Skeleton Notebook Deep Q-Learning Project (MHBF)"]},{"cell_type":"code","execution_count":1,"id":"wv1WjPbGQ35P","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1961,"status":"ok","timestamp":1720896980122,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"wv1WjPbGQ35P","outputId":"c143b056-fe0f-46d5-fc10-baa540cebae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/MHBF-DeepQ-Learning/gym_grid/')"]},{"cell_type":"code","execution_count":2,"id":"9d3afca4-944a-4a0e-a34b-bf5444ce7ffb","metadata":{"executionInfo":{"elapsed":7511,"status":"ok","timestamp":1720896989928,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"9d3afca4-944a-4a0e-a34b-bf5444ce7ffb"},"outputs":[],"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Import required packages\n","import gym\n","import gym_grid\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from IPython import display\n","from collections import namedtuple, deque\n","from tqdm import tqdm\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"id":"5599cf0b-5a75-44c1-b54b-79d1c94266a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1720896989929,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"5599cf0b-5a75-44c1-b54b-79d1c94266a1","outputId":"68d63087-44e4-4417-d180-a107d0650bf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    device = torch.device('mps')\n","else:\n","    device = torch.device('cpu')\n","print(device)"]},{"cell_type":"markdown","id":"5cba614b-63eb-4e8b-8c46-bad02735c0fb","metadata":{"id":"5cba614b-63eb-4e8b-8c46-bad02735c0fb"},"source":["# 0. Environment Implementation"]},{"cell_type":"code","execution_count":4,"id":"YND6IvKuVY5Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10318,"status":"ok","timestamp":1720897000243,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"YND6IvKuVY5Y","outputId":"c1256c55-bca6-4a39-dd94-e72066bf041b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pycolab in /usr/local/lib/python3.10/dist-packages (1.2)\n","Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from pycolab) (1.25.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pycolab) (1.16.0)\n"]}],"source":["!pip install pycolab"]},{"cell_type":"code","execution_count":5,"id":"e6077c2c-8f41-42d3-9aee-8803adedd189","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1720897000243,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"e6077c2c-8f41-42d3-9aee-8803adedd189","outputId":"40c2c4ff-eea6-41d8-87ca-a55fe2441add"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAxoAAABcCAYAAADpqcO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAChUlEQVR4nO3ZoU2EMRiA4f8IyzAKwaCwOBQDQE5fwgAoRkBhCAmCLQiDMEBR6DvxlstPnkc37VdR8aabMcZYAAAAQifHHgAAAPh/hAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAudNDF97dbmfOAQAArMTD427vGj8aAABATmgAAAA5oQEAAOSEBgAAkBMaAABATmgAAAA5oQEAAOSEBgAAkBMaAABATmgAAAA5oQEAAOSEBgAAkBMaAABATmgAAAA5oQEAAOSEBgAAkBMaAABATmgAAAA5oQEAAOSEBgAAkBMaAABATmgAAAA5oQEAAOROjz3Ar+uLz6n7n52/TN1/WZbl6+1y6v6z77D2+Zdl/Xcw/35rv8NfvIOZnq4upp9x8/w6/QyAY3v/nrv/x/127gEH8KMBAADkhAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAOaEBAADkhAYAAJATGgAAQE5oAAAAuc0YYxyy8O52O3sWAABgBR4ed3vX+NEAAAByQgMAAMgJDQAAICc0AACAnNAAAAByQgMAAMgJDQAAICc0AACAnNAAAAByQgMAAMgJDQAAICc0AACAnNAAAAByQgMAAMgJDQAAICc0AACAnNAAAAByQgMAAMgJDQAAICc0AACAnNAAAAByQgMAAMgJDQAAILcZY4xjDwEAAPwvfjQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAICc0AAAAHJCAwAAyAkNAAAgJzQAAIDcD2QQLa4waQoKAAAAAElFTkSuQmCC\n"},"metadata":{}}],"source":["# Visualize the environment\n","plt.figure(figsize=(10, 10))\n","# T-Maze Environment\n","env = gym.make(\"LinearTrack-v0\")\n","#env = gym.make(\"DeadlyGrid-v0\")\n","_, obs_to_render = env.reset_with_render()\n","env.reset()\n","env.render(obs_to_render)"]},{"cell_type":"code","execution_count":6,"id":"695a5017-5dce-4413-aee0-3b4050cd03a7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1720897002460,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"},"user_tz":-120},"id":"695a5017-5dce-4413-aee0-3b4050cd03a7","outputId":"51b2cb7d-8cbf-457a-b7b1-69be9b4d6779"},"outputs":[{"output_type":"stream","name":"stdout","text":["State space:  Box(0, 1, (3, 32, 4), uint8)\n","State shape:  (3, 32, 4)\n","Action space:  Discrete(3)\n","Number of actions:  3\n"]}],"source":["print('State space: ', env.observation_space)\n","print('State shape: ', env.observation_space.shape)\n","print('Action space: ', env.action_space)\n","print('Number of actions: ', env.action_space.n)"]},{"cell_type":"markdown","id":"858d0861-0176-43bb-a699-e2498dd9bdfb","metadata":{"id":"858d0861-0176-43bb-a699-e2498dd9bdfb"},"source":["# 1. Definition of model and params"]},{"cell_type":"code","execution_count":7,"id":"c47b7035-60dd-4b62-950c-043fe2c47f61","metadata":{"id":"c47b7035-60dd-4b62-950c-043fe2c47f61","executionInfo":{"status":"ok","timestamp":1720897004113,"user_tz":-120,"elapsed":495,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"}}},"outputs":[],"source":["# Discount factor\n","GAMMA = 0.99\n","# Learning rate\n","LEARNING_RATE = 0.001\n","# Capacity of the replay buffer\n","BUFFER_SIZE = 1000\n","# Update target net every ... episodes\n","UPDATE_EVERY= 500\n","# Batch size\n","BATCH_SIZE = 128\n","# Eval Episode\n","EVAL_EPISODE = 500\n","# Number of eval\n","N_EVAL = 50\n","# Hidden Units\n","HIDDEN_UNITS = 128\n","# Hidden layers\n","HIDDEN_LAYERS = 1\n","# Number of training episodes\n","N_EPISODES = 30000\n","# Initial value of epsilon\n","EPSILON_START = 1.0\n","# End value of epsilon\n","EPSILON_END = 0.01\n","# Epsilon decay\n","EPSILON_DECAY = (EPSILON_START - EPSILON_END) / N_EPISODES\n","# Initial value of epsilon\n","BETA_START = 0.4\n","# End value of epsilon\n","BETA_END = 1.0\n","# Epsilon decay\n","BETA_DECAY = (BETA_START - BETA_END) / N_EPISODES\n","# SEED\n","SEED = 1\n","\n","params = {'gamma': GAMMA, 'lr': LEARNING_RATE, 'bacth_size': BATCH_SIZE,\n","          'buffer_size': BUFFER_SIZE, 'update_step': UPDATE_EVERY,\n","          'hidden_unit': HIDDEN_UNITS, 'hidden_laye': HIDDEN_LAYERS,'n_episode': N_EPISODES}"]},{"cell_type":"code","execution_count":8,"id":"c03cf8c0-edc2-4c56-b4ab-4d88af756c2b","metadata":{"id":"c03cf8c0-edc2-4c56-b4ab-4d88af756c2b","executionInfo":{"status":"ok","timestamp":1720897005497,"user_tz":-120,"elapsed":339,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"}}},"outputs":[],"source":["class DQN(nn.Module):\n","    def __init__(self, input_dim, output_dim, hidden_units, hidden_layers):\n","        super(DQN, self).__init__()\n","\n","        self.action_space_size = output_dim\n","        self.hidden_layers = hidden_layers\n","        self.layer_in = nn.Linear(input_dim, hidden_units)\n","        self.hidden_layer= nn.Linear(hidden_units, hidden_units)\n","        self.layer_out = nn.Linear(hidden_units, output_dim)\n","\n","    def forward(self, x):\n","        x = F.relu(self.layer_in(x))\n","        for i in range(self.hidden_layers):\n","            x = F.relu(self.hidden_layer(x))\n","        x = self.layer_out(x)\n","        return x\n","\n","    def action(self, state, epsilon):\n","        if random.random() > epsilon:\n","            q_value = self.forward(state)\n","            action  = int(torch.argmax(q_value, dim=-1))\n","        else:\n","            action = random.randrange(self.action_space_size)\n","        return action"]},{"cell_type":"code","execution_count":9,"id":"4c3d24d4-28ad-4357-ab02-706476e10201","metadata":{"id":"4c3d24d4-28ad-4357-ab02-706476e10201","executionInfo":{"status":"ok","timestamp":1720897006459,"user_tz":-120,"elapsed":4,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"}}},"outputs":[],"source":["def test_agent(model, gamma):\n","    done = False\n","    episode_return = 0\n","    i = 0\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    with torch.no_grad():\n","        while not done:\n","            action = model.action(state, 0)\n","            state, reward, done, info = env.step(action)\n","            state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","            episode_return += gamma**i * reward\n","            i += 1\n","    return episode_return"]},{"cell_type":"code","source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)"],"metadata":{"id":"-9W_mSDJI_Am","executionInfo":{"status":"ok","timestamp":1720897007384,"user_tz":-120,"elapsed":4,"user":{"displayName":"Kevin Ferreira","userId":"05822166458633220249"}}},"id":"-9W_mSDJI_Am","execution_count":10,"outputs":[]},{"cell_type":"markdown","id":"93f24766-bdb9-43a4-bd58-0af0a20d6ac7","metadata":{"id":"93f24766-bdb9-43a4-bd58-0af0a20d6ac7"},"source":["# 2. Baseline"]},{"cell_type":"code","execution_count":null,"id":"2948b05e-5a16-49fd-81c7-4ddf3f81d1fa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"2948b05e-5a16-49fd-81c7-4ddf3f81d1fa","outputId":"d5bef05c-31d0-4db0-95db-a3b065f531f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":[" 10%|â–ˆ         | 3103/30000 [00:45<07:39, 58.50it/s]"]}],"source":["set_seed(SEED)\n","model_baseline = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                     env.action_space.n,\n","                     HIDDEN_UNITS,\n","                     HIDDEN_LAYERS).to(device)\n","optimizer = optim.Adam(params=model_baseline.parameters(), lr=LEARNING_RATE)\n","\n","results_baseline = {\n","    'params' : params,\n","    'epochs_save' : [],\n","    'weights': {},\n","    'rewards_test': [],\n","    'rewards_train': []\n","}\n","\n","step = 0\n","eps = EPSILON_START\n","\n","for step in tqdm(range(N_EPISODES)):\n","    done = False\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    r_train = 0\n","    result_train = []\n","    states = []\n","    actions = []\n","    rewards = []\n","    next_states = []\n","    dones = []\n","    while not done:\n","        action = model_baseline.action(state, eps)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = torch.tensor(next_state, dtype=torch.float32).flatten().to(device)\n","        r_train += reward\n","        states.append(state)\n","        actions.append(action)\n","        rewards.append(reward)\n","        next_states.append(next_state)\n","        dones.append(done)\n","        state = next_state\n","\n","    states = torch.stack(states).to(device)\n","    actions = torch.tensor(actions).to(device)\n","    rewards = torch.tensor(rewards).to(device)\n","    next_states = torch.stack(next_states).to(device)\n","    dones = torch.tensor(dones, dtype=torch.float32).to(device)\n","\n","    next_state_values = model_baseline(next_state).max().detach()\n","    state_action_values = model_baseline(state)[action]\n","\n","    expected_q_value = reward + GAMMA * next_state_values * (1 - done)\n","    loss = nn.MSELoss()(state_action_values, expected_q_value)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    result_train.append(r_train)\n","\n","    if step%EVAL_EPISODE == 0:\n","        r_test = []\n","        for j in range(N_EVAL):\n","            r = test_agent(model_baseline, GAMMA)\n","            r_test.append(r)\n","\n","        results_baseline['weights'][step] = model_baseline.state_dict()\n","        results_baseline['rewards_test'].append(np.mean(r_test))\n","        results_baseline['rewards_train'].append(np.mean(result_train))\n","        result_train = []\n","        results_baseline['epochs_save'].append(step)\n","\n","        display.clear_output(True)\n","        plt.plot(results_baseline['epochs_save'], results_baseline['rewards_train'], label = \"reward train\")\n","        plt.plot(results_baseline['epochs_save'], results_baseline['rewards_test'], label = \"reward test\")\n","        plt.legend()\n","        plt.show()\n","\n","    eps -= EPSILON_DECAY\n","    step += 1\n","torch.save(results_baseline, 'results_baseline.pth')"]},{"cell_type":"code","execution_count":null,"id":"a5bac821-daf9-486c-b87c-95a0c7ab245f","metadata":{"id":"a5bac821-daf9-486c-b87c-95a0c7ab245f"},"outputs":[],"source":["state, obs_to_render = env.reset_with_render()\n","state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","env.render(obs_to_render)\n","done = False\n","tot_rew_test = 0\n","with torch.no_grad():\n","        while not done:\n","            action = model_baseline.action(state, 0)\n","            state, rew , done, _, obs_to_render = env.step_with_render(action)\n","            state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","            tot_rew_test += rew\n","            env.render(obs_to_render)\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","print(tot_rew_test)"]},{"cell_type":"markdown","id":"1433e377-490a-4d07-9f75-1282e3cb6be4","metadata":{"id":"1433e377-490a-4d07-9f75-1282e3cb6be4"},"source":["# 3. Replay Buffer"]},{"cell_type":"code","execution_count":null,"id":"6244f4c8-f179-497e-abea-3ab095b1ec8f","metadata":{"id":"6244f4c8-f179-497e-abea-3ab095b1ec8f"},"outputs":[],"source":["class ReplayBuffer:\n","    def __init__(self, data_names, buffer_size, batch_size):\n","        self.data_keys = data_names\n","        self.data_dict = {}\n","        self.buffer_size = buffer_size\n","        self.batch_size = batch_size\n","        self.reset()\n","\n","    def reset(self):\n","        for name in self.data_keys:\n","            self.data_dict[name] = deque(maxlen=self.buffer_size)\n","\n","    def push(self, data):\n","        \"\"\"Add a transition to the buffer.\"\"\"\n","        for key in self.data_keys:\n","            self.data_dict[key].append(data[key])\n","\n","    def sample(self):\n","        \"\"\"Sample a batch of transitions.\"\"\"\n","        indices = random.sample(range(len(self)), self.batch_size)\n","        batch = [{key: self.data_dict[key][i] for key in self.data_keys} for i in indices]\n","        return batch\n","\n","    def __len__(self):\n","        return len(next(iter(self.data_dict.values())))"]},{"cell_type":"code","execution_count":null,"id":"e2b56db6-608b-4193-a7f4-b5f30cef1b0c","metadata":{"id":"e2b56db6-608b-4193-a7f4-b5f30cef1b0c"},"outputs":[],"source":["set_seed(SEED)\n","model_replay_buffer = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","replay_buffer = ReplayBuffer(['state', 'action', 'reward', 'next_state', 'done'],\n","                             BUFFER_SIZE, BATCH_SIZE)\n","\n","optimizer = optim.Adam(params=model_replay_buffer.parameters(), lr=LEARNING_RATE)\n","\n","step = 0\n","\n","results_rb = {\n","    'params' : params,\n","    'epochs_save' : [],\n","    'weights': {},\n","    'rewards_test': [],\n","    'rewards_train': []\n","}\n","\n","eps = EPSILON_START\n","for step in tqdm(range(N_EPISODES)):\n","    done = False\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    result_train = []\n","    r_train = 0\n","    while not done:\n","        action = model_replay_buffer.action(state, eps)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = torch.tensor(next_state, dtype=torch.float32).flatten().to(device)\n","        replay_buffer.push({'state':state, 'action':action, 'reward':reward,\n","                            'next_state':next_state, 'done':done})\n","        r_train += reward\n","\n","    result_train.append(r_train)\n","\n","    if len(replay_buffer) >= replay_buffer.batch_size:\n","        batch = replay_buffer.sample()\n","\n","        states = torch.stack([b['state'] for b in batch]).to(device)\n","        actions = torch.tensor([b['action'] for b in batch]).to(device)\n","        rewards = torch.tensor([b['reward'] for b in batch]).to(device)\n","        next_states = torch.stack([b['next_state'] for b in batch]).to(device)\n","        dones = torch.tensor([b['done'] for b in batch], dtype=torch.float32).to(device)\n","\n","        state_action_values = model_replay_buffer(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n","        next_state_values = model_replay_buffer(next_states).max(1)[0].detach()\n","        expected_q_values = rewards + GAMMA * next_state_values * (1 - dones)\n","\n","        loss = nn.MSELoss()(state_action_values, expected_q_value)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if step%EVAL_EPISODE == 0:\n","        r_test = []\n","        for j in range(10):\n","            r = test_agent(model_replay_buffer, GAMMA)\n","            r_test.append(r)\n","        results_rb['weights'][step] = model_replay_buffer.state_dict()\n","        results_rb['rewards_test'].append(np.mean(r_test))\n","        results_rb['rewards_train'].append(np.mean(result_train))\n","        result_train = []\n","        results_rb['epochs_save'].append(step)\n","\n","        display.clear_output(True)\n","        plt.plot(results_rb['epochs_save'], results_rb['rewards_train'], label = \"reward train\")\n","        plt.plot(results_rb['epochs_save'],results_rb['rewards_test'], label = \"reward test\")\n","        plt.legend()\n","        plt.show()\n","\n","    eps -= EPSILON_DECAY\n","    step += 1\n","torch.save(results_rb, 'results_rb.pth')"]},{"cell_type":"code","source":["state, obs_to_render = env.reset_with_render()\n","state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","env.render(obs_to_render)\n","done = False\n","tot_rew_test = 0\n","with torch.no_grad():\n","        while not done:\n","            action = model_replay_buffer.action(state, 0)\n","            state, rew , done, _, obs_to_render = env.step_with_render(action)\n","            state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","            tot_rew_test += rew\n","            env.render(obs_to_render)\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","print(tot_rew_test)"],"metadata":{"id":"JwiaZpgjTP83"},"id":"JwiaZpgjTP83","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"62510892-1faa-41c1-9bc3-239064c2f727","metadata":{"id":"62510892-1faa-41c1-9bc3-239064c2f727"},"source":["# 4. Target Network"]},{"cell_type":"code","execution_count":null,"id":"76316b1c-614d-4aa0-93fb-1219e3cc6e07","metadata":{"id":"76316b1c-614d-4aa0-93fb-1219e3cc6e07"},"outputs":[],"source":["set_seed(SEED)\n","model_tn = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_tn_target = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_tn_target.load_state_dict(model_tn.state_dict())\n","\n","replay_buffer = ReplayBuffer(['state', 'action', 'reward', 'next_state', 'done'],\n","                             BUFFER_SIZE, BATCH_SIZE)\n","\n","optimizer = optim.Adam(params=model_tn.parameters(), lr=LEARNING_RATE)\n","\n","step = 0\n","\n","results_tm = {\n","    'params' : params,\n","    'epochs_save' : [],\n","    'weights': {},\n","    'rewards_test': [],\n","    'rewards_train': []\n","}\n","\n","eps = EPSILON_START\n","for step in tqdm(range(N_EPISODES)):\n","    done = False\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    r_train = 0\n","    result_train = []\n","    while not done:\n","        action = model_tn.action(state, eps)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = torch.tensor(next_state, dtype=torch.float32).flatten().to(device)\n","        replay_buffer.push({'state':state, 'action':action, 'reward':reward,\n","                            'next_state':next_state, 'done':done})\n","        r_train += reward\n","\n","    result_train.append(r_train)\n","\n","    if len(replay_buffer) >= replay_buffer.batch_size:\n","        batch = replay_buffer.sample()\n","\n","        states = torch.stack([b['state'] for b in batch]).to(device)\n","        actions = torch.tensor([b['action'] for b in batch]).to(device)\n","        rewards = torch.tensor([b['reward'] for b in batch]).to(device)\n","        next_states = torch.stack([b['next_state'] for b in batch]).to(device)\n","        dones = torch.tensor([b['done'] for b in batch], dtype=torch.float32).to(device)\n","\n","        state_action_values = model_tn(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n","        next_state_values = model_tn_target(next_states).max(1)[0].detach()\n","        expected_q_values = rewards + GAMMA * next_state_values * (1 - dones)\n","\n","        loss = nn.MSELoss()(state_action_values, expected_q_value)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if step % UPDATE_EVERY == 0:\n","        model_tn_target.load_state_dict(model_tn.state_dict())\n","\n","    if step%EVAL_EPISODE == 0:\n","        r_test = []\n","        for j in range(10):\n","            r = test_agent(model_tn, GAMMA)\n","            r_test.append(r)\n","        results_tm['weights'][step] = model_tn.state_dict()\n","        results_tm['rewards_test'].append(np.mean(r_test))\n","        results_tm['epochs_save'].append(step)\n","        results_tm['rewards_train'].append(np.mean(result_train))\n","        result_train = []\n","\n","        display.clear_output(True)\n","        plt.plot(results_tm['epochs_save'], results_tm['rewards_train'], label = \"reward train\")\n","        plt.plot(results_tm['epochs_save'], results_tm['rewards_test'], label = \"reward test\")\n","        plt.legend()\n","        plt.show()\n","\n","    eps -= EPSILON_DECAY\n","torch.save(results_tm, 'results_tm.pth')"]},{"cell_type":"code","source":["state, obs_to_render = env.reset_with_render()\n","state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","env.render(obs_to_render)\n","done = False\n","tot_rew_test = 0\n","with torch.no_grad():\n","        while not done:\n","            action = model_tn.action(state, 0)\n","            state, rew , done, _, obs_to_render = env.step_with_render(action)\n","            state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","            tot_rew_test += rew\n","            env.render(obs_to_render)\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","print(tot_rew_test)"],"metadata":{"id":"D-Gd5wSWTeBC"},"id":"D-Gd5wSWTeBC","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"4a1d0713-4f56-4560-bbbf-bea2c0cb3909","metadata":{"id":"4a1d0713-4f56-4560-bbbf-bea2c0cb3909"},"source":["# 5. Loss Function Comparaison"]},{"cell_type":"code","execution_count":null,"id":"43f1d5d2-ee04-4cc8-bca7-71ff2ef1695c","metadata":{"id":"43f1d5d2-ee04-4cc8-bca7-71ff2ef1695c"},"outputs":[],"source":["set_seed(SEED)\n","model_lf = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_lf_target = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_lf_target.load_state_dict(model_lf.state_dict())\n","\n","replay_buffer = ReplayBuffer(['state', 'action', 'reward', 'next_state', 'done'],\n","                             BUFFER_SIZE, BATCH_SIZE)\n","\n","optimizer = optim.Adam(params=model_lf.parameters(), lr=LEARNING_RATE)\n","\n","results_lf = {\n","    'params' : params,\n","    'epochs_save' : [],\n","    'weights': {},\n","    'rewards_test': [],\n","    'rewards_train': []\n","}\n","\n","step = 0\n","eps = EPSILON_START\n","for step in tqdm(range(N_EPISODES)):\n","    done = False\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    r_train = 0\n","    result_train = []\n","    while not done:\n","        action = model_lf.action(state, eps)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = torch.tensor(next_state, dtype=torch.float32).flatten().to(device)\n","        replay_buffer.push({'state':state, 'action':action, 'reward':reward,\n","                            'next_state':next_state, 'done':done})\n","        r_train += reward\n","\n","    result_train.append(r_train)\n","\n","    if len(replay_buffer) >= replay_buffer.batch_size:\n","        batch = replay_buffer.sample()\n","\n","        states = torch.stack([b['state'] for b in batch]).to(device)\n","        actions = torch.tensor([b['action'] for b in batch]).to(device)\n","        rewards = torch.tensor([b['reward'] for b in batch]).to(device)\n","        next_states = torch.stack([b['next_state'] for b in batch]).to(device)\n","        dones = torch.tensor([b['done'] for b in batch], dtype=torch.float32).to(device)\n","\n","        state_action_values = model_lf(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n","        next_state_values = model_lf_target(next_states).max(1)[0].detach()\n","        expected_q_values = rewards + GAMMA * next_state_values * (1 - dones)\n","\n","        loss = nn.SmoothL1Loss()(state_action_values, expected_q_value)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if step % UPDATE_EVERY == 0:\n","        model_lf_target.load_state_dict(model_lf.state_dict())\n","\n","    if step%EVAL_EPISODE == 0:\n","        r_test = []\n","        for j in range(10):\n","            r = test_agent(model_lf, GAMMA)\n","            r_test.append(r)\n","        results_lf['weights'][step] = model_lf.state_dict()\n","        results_lf['rewards_test'].append(np.mean(r_test))\n","        results_lf['epochs_save'].append(step)\n","        results_lf['rewards_train'].append(np.mean(result_train))\n","        result_train = []\n","\n","        display.clear_output(True)\n","        plt.plot(results_lf['epochs_save'], results_lf['rewards_train'], label = \"reward train\")\n","        plt.plot(results_lf['epochs_save'], results_lf['rewards_test'], label = \"reward test\")\n","        plt.legend()\n","        plt.show()\n","\n","    eps -= EPSILON_DECAY\n","    step += 1\n","torch.save(results_lf, 'results_lf.pth')"]},{"cell_type":"code","source":["state, obs_to_render = env.reset_with_render()\n","state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","env.render(obs_to_render)\n","done = False\n","tot_rew_test = 0\n","with torch.no_grad():\n","        while not done:\n","            action = model_lf.action(state, 0)\n","            state, rew , done, _, obs_to_render = env.step_with_render(action)\n","            state = torch.tensor(state, dtype=torch.float32).flatten().to(device)\n","            tot_rew_test += rew\n","            env.render(obs_to_render)\n","            display.display(plt.gcf())\n","            display.clear_output(wait=True)\n","print(tot_rew_test)"],"metadata":{"id":"3YcaOUF_TiMR"},"id":"3YcaOUF_TiMR","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"d74ac533-ed9e-454d-be44-d5de6c28856d","metadata":{"id":"d74ac533-ed9e-454d-be44-d5de6c28856d"},"source":["# 6. Prioritized Experience Replay"]},{"cell_type":"code","source":["class PrioritizedReplayBuffer:\n","    def __init__(self, data_names, buffer_size, batch_size, alpha=0.6):\n","        self.data_keys = data_names\n","        self.data_dict = {}\n","        self.buffer_size = buffer_size\n","        self.alpha = alpha\n","        self.priorities = deque(maxlen=buffer_size)\n","        self.batch_size = batch_size\n","        self.reset()\n","\n","    def reset(self):\n","        for name in self.data_keys:\n","            self.data_dict[name] = deque(maxlen=self.buffer_size)\n","        self.priorities = deque(maxlen=self.buffer_size)\n","\n","    def push(self, data):\n","        \"\"\"Add a transition to the buffer.\"\"\"\n","        max_priority = max(self.priorities, default=1.0)\n","        self.priorities.append(max_priority)\n","        for key in self.data_keys:\n","            self.data_dict[key].append(data[key])\n","\n","    def sample(self, beta=0.4):\n","        \"\"\"Sample a batch of transitions.\"\"\"\n","        if len(self) == self.buffer_size:\n","            priorities = np.array(self.priorities, dtype=np.float32)\n","            scaled_priorities = priorities ** self.alpha\n","            sample_probs = scaled_priorities / sum(scaled_priorities)\n","        else:\n","            sample_probs = np.ones(len(self)) / len(self)\n","\n","        indices = np.random.choice(len(self), self.batch_size, p=sample_probs)\n","        samples = [{key: self.data_dict[key][i] for key in self.data_keys} for i in indices]\n","\n","        weights = (len(self) * sample_probs[indices]) ** (-beta)\n","        weights /= weights.max()\n","        return samples, weights, indices\n","\n","    def update_priorities(self, indices, td_errors):\n","        for i, td_error in zip(indices, td_errors):\n","            self.priorities[i] = abs(td_error) + 1e-6\n","\n","    def __len__(self):\n","        return len(next(iter(self.data_dict.values())))"],"metadata":{"id":"yj6AojzHK5l3"},"id":"yj6AojzHK5l3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(SEED)\n","model_per = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_per_target = DQN(env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2],\n","                          env.action_space.n,\n","                          HIDDEN_UNITS,\n","                          HIDDEN_LAYERS).to(device)\n","\n","model_per_target.load_state_dict(model_per.state_dict())\n","\n","replay_buffer = PrioritizedReplayBuffer(['state', 'action', 'reward', 'next_state', 'done'],\n","                             BUFFER_SIZE, BATCH_SIZE)\n","\n","optimizer = optim.Adam(params=model_per.parameters(), lr=LEARNING_RATE)\n","\n","results_per = {\n","    'params' : params,\n","    'epochs_save' : [],\n","    'weights': {},\n","    'rewards_test': [],\n","    'rewards_train': []\n","}\n","\n","step = 0\n","eps  = EPSILON_START\n","beta = BETA_START\n","for step in tqdm(range(N_EPISODES)):\n","    done = False\n","    state = torch.tensor(env.reset(), dtype=torch.float32).flatten().to(device)\n","    r_train = 0\n","    while not done:\n","        action = model_per.action(state, eps)\n","        next_state, reward, done, info = env.step(action)\n","        next_state = torch.tensor(next_state, dtype=torch.float32).flatten().to(device)\n","        replay_buffer.push({'state':state, 'action':action, 'reward':reward,\n","                            'next_state':next_state, 'done':done})\n","        r_train += reward\n","\n","    results_per['rewards_train'].append(r_train)\n","\n","    if len(replay_buffer) > replay_buffer.batch_size:\n","        batch, weights, indices = replay_buffer.sample(beta)\n","        for b in batch:\n","\n","            next_state_values = model_per_target(b['next_state']).max().detach()\n","            state_action_values = model_per(b['state'])[b['action']]\n","\n","            expected_q_value = b['reward'] + GAMMA * next_state_values * (1 - b['done'])\n","\n","            td_errors = state_action_values - expected_q_value\n","            loss = torch.mean((state_action_values - expected_q_value ** 2) * weights)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            replay_buffer.update_priorities(indices, td_errors.detach().cpu().numpy())\n","\n","    if step % UPDATE_EVERY == 0:\n","        model_per_target.load_state_dict(model_per.state_dict())\n","\n","    if step%EVAL_EPISODE == 0:\n","        r_test = []\n","        for j in range(10):\n","            r = test_agent(model_per, GAMMA)\n","            r_test.append(r)\n","        results_per['weights'][step] = model_per.state_dict()\n","        results_per['rewards_test'].append(np.mean(r_test))\n","        results_per['epochs_save'].append(step)\n","\n","        display.clear_output(True)\n","        plt.plot(results_per['rewards_train'], label = \"reward train\")\n","        plt.plot(results_per['epochs_save'], results_per['rewards_test'], label = \"reward test\")\n","        plt.legend()\n","        plt.show()\n","\n","    eps -= EPSILON_DECAY\n","    step += 1\n","    beta = min(1.0, beta + BETA_DECAY)\n","torch.save(results_per, 'results_per.pth')"],"metadata":{"id":"TZ071H2oJ6bT"},"id":"TZ071H2oJ6bT","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}